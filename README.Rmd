---
title: "Combine UCLA Phonetics Lab Archive metadata with Glottolog metadata and do some stats and tests"
author: "Steven Moran"
date: "2023-10-09"
output: 
  github_document:
    toc: true

---

Load some libraries

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(knitr)
```

***

# Overview

I took the the UCLA Phonetics Archive:

* http://archive.phonetics.ucla.edu/Language%20Indices/index_available.htm

And first created a CSV file of their language names and ISO codes by hand.

Then we load the hand created table.

```{r, warning=FALSE, message=FALSE}
ucla <- read_csv('ucla_metadata.csv')
```

Then load the Glottolog geo data.

```{r, warning=FALSE, message=FALSE}
glottolog_geo <- read_csv(url('https://cdstar.eva.mpg.de//bitstreams/EAEA0-B701-6328-C3E3-0/languages_and_dialects_geo.csv'))
```

Let's see what doesn't match by joining them. Actually, looks surprisingly pretty good -- only a few retired ISO codes that we can curate by hand, if needed.

```{r}
ucla$iso_6393 <- tolower(ucla$`Ethnologue Code`)
ucla_glottlog <- left_join(ucla, glottolog_geo, by=c("iso_6393"="isocodes"))
```

Now we can map them. :)

```{r}
ggplot(data=ucla_glottlog, aes(x=longitude, y=latitude)) + 
  borders("world", colour="gray50", fill="gray50") + 
  geom_point() +
  theme_bw()
```


Let's add in language family data. This must be downloaded from Glottolog (updated per release) instead of read directly from the website, like above.

```{r, warning=FALSE, message=FALSE}
glottolog_families <- read_csv('glottolog_languoid/languoid.csv')
```

Join them again.

```{r}
ucla_glottlog <- left_join(ucla_glottlog, glottolog_families)
```

And map them by family.

```{r}
ggplot(data=ucla_glottlog, aes(x=longitude, y=latitude, color=family_id)) + 
  borders("world", colour="gray50", fill="gray50") + 
  geom_point() +
  theme_bw() +
  theme(legend.position="none")
```

Write the combined data as csv.

```{r}
head(ucla_glottlog) %>% kable()
write_csv(ucla_glottlog, 'ucla_glottlog.csv')
```

How many languages (according to ISO 639-3 code) are present in the sample?

```{r}
# Less than the number of ISO codes
nrow(ucla_glottlog %>% select(glottocode) %>% distinct())
nrow(ucla_glottlog %>% select(iso_6393) %>% distinct())
```


How many language families are present in the sample?

```{r}
nrow(ucla_glottlog %>% select(family_id) %>% distinct())
```


# Explore VoxAngeles TextGrid data

Read in Eleanor's TextGrid table. First I converted it to UTF-8 (from UTF-16) and to CSV (from TSV).

```{r, warning=FALSE, message=FALSE}
df <- read_csv('ucla_durations.csv')
```

Get UCLA phoneme counts per language / phone.

```{r}
lang_phone_count <- df %>% group_by(lang, phone) %>% summarize(phoneme_count = n())
```

Get UCLA phoneme counts per language.

```{r}
ucla_lang_phoneme_count <- lang_phone_count %>% group_by(lang) %>% summarize(ucla_phonemes = n())
```

Get PHOIBLE CLDF data.

```{r, warning=FALSE, message=FALSE}
values <- read_csv(url('https://raw.githubusercontent.com/cldf-datasets/phoible/master/cldf/values.csv'))
languages <- read_csv(url('https://raw.githubusercontent.com/cldf-datasets/phoible/master/cldf/languages.csv'))
inventories <- read_csv(url('https://raw.githubusercontent.com/cldf-datasets/phoible/master/cldf/inventories.csv'))
parameters <- read_csv(url('https://raw.githubusercontent.com/cldf-datasets/phoible/master/cldf/parameters.csv'))
```

Merge into a data frame for the language index with counts.

```{r, warning=FALSE, message=FALSE}
phoible <- values %>% select(Language_ID, Inventory_ID) %>% distinct()
phoible <- left_join(phoible, inventories, by=c("Inventory_ID" = "ID"))
phoible <- phoible %>% rename(Source_name = Name)
phoible <- left_join(phoible, languages, by=c("Language_ID" = "ID"))
```

Merge CLDF inventories together with languages index.

```{r}
tmp <- phoible %>% select(Glottocode, Name, ISO639P3code, count_phonemes) %>% group_by(ISO639P3code) %>% filter(row_number()==1)

ucla_phoible_phoneme_counts <- left_join(ucla_lang_phoneme_count, tmp, by=c("lang"="ISO639P3code"))
```

We have some NAs in the phoible.count_phonemes data column. Replace with 0.

```{r}
# ucla_phoible_phoneme_counts$count_phonemes <- ucla_phoible_phoneme_counts$count_phonemes %>% replace_na(0)
```

Get the delta between the phoneme counts and compare coverage. This doesn't compare phonemes -- just counts between what is unique in VoxAngeles and the number of phonemes in the inventory in PHOIBLE.

To do a fair comparison between the CMU-UCLA / VoxAngeles corpus and PHOIBLE the segments would have to follow the phoible segment conventions.

```{r}
ucla_phoible_phoneme_counts$delta <- abs(ucla_phoible_phoneme_counts$ucla_phonemes - ucla_phoible_phoneme_counts$count_phonemes)

ucla_phoible_phoneme_counts %>% kable()
```


# Tests

```{r}
lang_phone_count %>% filter(lang=="lit") %>% distinct(phone) %>% kable()
```

# TODOS

In progress:

* read in Eleanor's table and do some rough stats

Refs if checking differences in phoneme inventories:

* https://blogs.umass.edu/phonolist/2019/12/03/dockum-bowern-2019-swadesh-wordlists-are-not-long-enough/

* https://www.researchgate.net/publication/332751956_Swadesh_lists_are_not_long_enough_Drawing_phonological_generalizations_from_limited_data

* https://researchprofiles.anu.edu.au/en/publications/blowing-in-the-wind-using-north-wind-and-the-sun-texts-to-sample-


